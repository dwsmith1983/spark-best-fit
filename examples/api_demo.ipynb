{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark-dist-fit API Demo\n",
    "\n",
    "This notebook demonstrates the complete API for the `spark-dist-fit` library, including:\n",
    "\n",
    "1. **Configuration** - FitConfig, PlotConfig, SparkConfig, and AppConfig\n",
    "2. **Config Loading** - From code, strings, and files (HOCON/YAML/JSON)\n",
    "3. **Distribution Fitting** - Using DistributionFitter\n",
    "4. **Working with Results** - FitResults and FitResult objects\n",
    "5. **Plotting** - Visualization with PlotConfig\n",
    "6. **Convenience Methods** - One-line config loading with `from_config()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the required modules and create a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import all public API components\n",
    "from spark_dist_fit import (\n",
    "    DistributionFitter,\n",
    "    FitConfig,\n",
    "    PlotConfig,\n",
    "    SparkConfig,\n",
    "    AppConfig,\n",
    "    DEFAULT_EXCLUDED_DISTRIBUTIONS,\n",
    ")\n",
    "\n",
    "# Create Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"API-Demo\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"10\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "We'll create sample data from known distributions for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Normal distribution data\n",
    "normal_data = np.random.normal(loc=50, scale=10, size=50_000)\n",
    "df_normal = spark.createDataFrame([(float(x),) for x in normal_data], [\"value\"])\n",
    "\n",
    "# Exponential distribution data (non-negative)\n",
    "exp_data = np.random.exponential(scale=5, size=50_000)\n",
    "df_exp = spark.createDataFrame([(float(x),) for x in exp_data], [\"value\"])\n",
    "\n",
    "# Gamma distribution data\n",
    "gamma_data = np.random.gamma(shape=2.0, scale=2.0, size=50_000)\n",
    "df_gamma = spark.createDataFrame([(float(x),) for x in gamma_data], [\"value\"])\n",
    "\n",
    "print(f\"Normal data: {df_normal.count():,} rows, mean={normal_data.mean():.2f}, std={normal_data.std():.2f}\")\n",
    "print(f\"Exponential data: {df_exp.count():,} rows, mean={exp_data.mean():.2f}\")\n",
    "print(f\"Gamma data: {df_gamma.count():,} rows, mean={gamma_data.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Configuration\n",
    "\n",
    "spark-dist-fit uses frozen dataclasses for type-safe, immutable configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 FitConfig - Distribution Fitting Configuration\n",
    "\n",
    "`FitConfig` controls histogram computation, sampling, and distribution selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default configuration\n",
    "default_fit_config = FitConfig()\n",
    "print(\"Default FitConfig:\")\n",
    "print(f\"  bins: {default_fit_config.bins}\")\n",
    "print(f\"  use_rice_rule: {default_fit_config.use_rice_rule}\")\n",
    "print(f\"  support_at_zero: {default_fit_config.support_at_zero}\")\n",
    "print(f\"  enable_sampling: {default_fit_config.enable_sampling}\")\n",
    "print(f\"  sample_threshold: {default_fit_config.sample_threshold:,}\")\n",
    "print(f\"  max_sample_size: {default_fit_config.max_sample_size:,}\")\n",
    "print(f\"  max_sample_fraction: {default_fit_config.max_sample_fraction}\")\n",
    "print(f\"  random_seed: {default_fit_config.random_seed}\")\n",
    "print(f\"  excluded_distributions: {len(default_fit_config.excluded_distributions)} distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom configuration\n",
    "custom_fit_config = FitConfig(\n",
    "    bins=100,                      # More bins for better resolution\n",
    "    use_rice_rule=False,           # Don't auto-calculate bins\n",
    "    support_at_zero=True,          # Only fit non-negative distributions\n",
    "    enable_sampling=True,          # Enable adaptive sampling\n",
    "    sample_fraction=0.3,           # Sample 30% of data\n",
    "    max_sample_size=500_000,       # Cap samples at 500K\n",
    "    random_seed=123,               # Custom seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Custom FitConfig (for non-negative data):\")\n",
    "print(f\"  bins: {custom_fit_config.bins}\")\n",
    "print(f\"  support_at_zero: {custom_fit_config.support_at_zero}\")\n",
    "print(f\"  sample_fraction: {custom_fit_config.sample_fraction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing excluded distributions\n",
    "print(f\"\\nDefault excluded distributions ({len(DEFAULT_EXCLUDED_DISTRIBUTIONS)}):\")\n",
    "for dist in sorted(DEFAULT_EXCLUDED_DISTRIBUTIONS):\n",
    "    print(f\"  - {dist}\")\n",
    "\n",
    "# Include a specific distribution that's excluded by default\n",
    "custom_exclusions = tuple(d for d in DEFAULT_EXCLUDED_DISTRIBUTIONS if d != \"wald\")\n",
    "config_with_wald = FitConfig(excluded_distributions=custom_exclusions)\n",
    "print(f\"\\nNow fitting 'wald' distribution (removed from exclusions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 PlotConfig - Visualization Configuration\n",
    "\n",
    "`PlotConfig` controls matplotlib figure settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default PlotConfig\n",
    "default_plot_config = PlotConfig()\n",
    "print(\"Default PlotConfig:\")\n",
    "print(f\"  figsize: {default_plot_config.figsize}\")\n",
    "print(f\"  dpi: {default_plot_config.dpi}\")\n",
    "print(f\"  show_histogram: {default_plot_config.show_histogram}\")\n",
    "print(f\"  histogram_alpha: {default_plot_config.histogram_alpha}\")\n",
    "print(f\"  pdf_linewidth: {default_plot_config.pdf_linewidth}\")\n",
    "print(f\"  save_format: {default_plot_config.save_format}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PlotConfig for presentations\n",
    "presentation_plot_config = PlotConfig(\n",
    "    figsize=(16, 10),\n",
    "    dpi=150,  # Lower DPI for notebook display\n",
    "    histogram_alpha=0.6,\n",
    "    pdf_linewidth=3,\n",
    "    title_fontsize=18,\n",
    "    label_fontsize=14,\n",
    "    legend_fontsize=12,\n",
    "    grid_alpha=0.4,\n",
    ")\n",
    "\n",
    "print(\"Presentation PlotConfig:\")\n",
    "print(f\"  figsize: {presentation_plot_config.figsize}\")\n",
    "print(f\"  title_fontsize: {presentation_plot_config.title_fontsize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 SparkConfig - Spark Session Configuration\n",
    "\n",
    "`SparkConfig` manages Spark session settings for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default SparkConfig\n",
    "default_spark_config = SparkConfig()\n",
    "print(\"Default SparkConfig:\")\n",
    "print(f\"  app_name: {default_spark_config.app_name}\")\n",
    "print(f\"  arrow_enabled: {default_spark_config.arrow_enabled}\")\n",
    "print(f\"  adaptive_enabled: {default_spark_config.adaptive_enabled}\")\n",
    "print(f\"  adaptive_coalesce_enabled: {default_spark_config.adaptive_coalesce_enabled}\")\n",
    "\n",
    "# Convert to Spark config dict\n",
    "spark_settings = default_spark_config.to_spark_config()\n",
    "print(\"\\nSpark settings dict:\")\n",
    "for k, v in spark_settings.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Config Immutability\n",
    "\n",
    "All config classes are frozen dataclasses - they cannot be modified after creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to modify config (will fail)\n",
    "try:\n",
    "    default_fit_config.bins = 200\n",
    "except AttributeError as e:\n",
    "    print(f\"Cannot modify frozen config: {e}\")\n",
    "\n",
    "# To change config values, create a new instance\n",
    "new_config = FitConfig(bins=200, support_at_zero=True)\n",
    "print(f\"\\nCreated new config with bins={new_config.bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Config Loading\n",
    "\n",
    "Configs can be loaded from HOCON, YAML, or JSON files/strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Config from String (HOCON format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FitConfig from HOCON string (flat structure - no nesting)\n",
    "hocon_string = \"\"\"\n",
    "bins = 75\n",
    "use_rice_rule = false\n",
    "support_at_zero = false\n",
    "enable_sampling = true\n",
    "sample_fraction = 0.25\n",
    "random_seed = 99\n",
    "\"\"\"\n",
    "\n",
    "config_from_string = FitConfig.from_string(hocon_string)\n",
    "print(\"FitConfig from HOCON string:\")\n",
    "print(f\"  bins: {config_from_string.bins}\")\n",
    "print(f\"  sample_fraction: {config_from_string.sample_fraction}\")\n",
    "print(f\"  random_seed: {config_from_string.random_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PlotConfig from HOCON string\n",
    "plot_hocon = \"\"\"\n",
    "figsize = [14, 8]\n",
    "dpi = 100\n",
    "histogram_alpha = 0.7\n",
    "pdf_linewidth = 2\n",
    "title_fontsize = 16\n",
    "\"\"\"\n",
    "\n",
    "plot_config_from_string = PlotConfig.from_string(plot_hocon)\n",
    "print(\"PlotConfig from HOCON string:\")\n",
    "print(f\"  figsize: {plot_config_from_string.figsize}\")\n",
    "print(f\"  dpi: {plot_config_from_string.dpi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Nested Config with AppConfig\n",
    "\n",
    "For HOCON files with nested structure (`fit{}`, `plot{}`, `spark{}`), use `AppConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested HOCON config (typical production format)\n",
    "nested_hocon = \"\"\"\n",
    "spark {\n",
    "    app_name = \"demo-app\"\n",
    "    arrow_enabled = true\n",
    "    adaptive_enabled = true\n",
    "}\n",
    "\n",
    "fit {\n",
    "    bins = 80\n",
    "    use_rice_rule = false\n",
    "    support_at_zero = false\n",
    "    enable_sampling = true\n",
    "    sample_fraction = 0.4\n",
    "    random_seed = 42\n",
    "}\n",
    "\n",
    "plot {\n",
    "    figsize = [12, 8]\n",
    "    dpi = 150\n",
    "    histogram_alpha = 0.5\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "app_config = AppConfig.from_string(nested_hocon)\n",
    "print(\"AppConfig from nested HOCON:\")\n",
    "print(f\"  spark.app_name: {app_config.spark.app_name}\")\n",
    "print(f\"  fit.bins: {app_config.fit.bins}\")\n",
    "print(f\"  fit.sample_fraction: {app_config.fit.sample_fraction}\")\n",
    "print(f\"  plot.figsize: {app_config.plot.figsize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Config from File\n",
    "\n",
    "Load configuration from a file (HOCON, YAML, or JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load from repository example config\n",
    "config_path = Path(\"../config/example.conf\")\n",
    "\n",
    "if config_path.exists():\n",
    "    app_config_from_file = AppConfig.from_file(str(config_path))\n",
    "    print(\"AppConfig from file:\")\n",
    "    print(f\"  File: {config_path}\")\n",
    "    print(f\"  spark.app_name: {app_config_from_file.spark.app_name}\")\n",
    "    print(f\"  fit.bins: {app_config_from_file.fit.bins}\")\n",
    "    print(f\"  fit.excluded_distributions: {len(app_config_from_file.fit.excluded_distributions)} distributions\")\n",
    "    print(f\"  plot.dpi: {app_config_from_file.plot.dpi}\")\n",
    "else:\n",
    "    print(f\"Config file not found: {config_path}\")\n",
    "    print(\"Run this notebook from the examples/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Distribution Fitting\n",
    "\n",
    "The `DistributionFitter` class is the main entry point for fitting distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Basic Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fitter with default config\n",
    "fitter = DistributionFitter()\n",
    "\n",
    "# Fit distributions to normal data (limit to 20 for demo speed)\n",
    "print(\"Fitting distributions to normal data...\")\n",
    "results_normal = fitter.fit(df_normal, column=\"value\", max_distributions=20)\n",
    "\n",
    "print(f\"\\nFitted {results_normal.count()} distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fitting with Custom Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for non-negative distributions only\n",
    "nonneg_config = FitConfig(\n",
    "    bins=100,\n",
    "    support_at_zero=True,  # Only fit non-negative distributions\n",
    "    enable_sampling=True,\n",
    ")\n",
    "\n",
    "fitter_nonneg = DistributionFitter(config=nonneg_config)\n",
    "\n",
    "print(\"Fitting non-negative distributions to exponential data...\")\n",
    "results_exp = fitter_nonneg.fit(df_exp, column=\"value\", max_distributions=15)\n",
    "\n",
    "print(f\"Fitted {results_exp.count()} non-negative distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Using from_config() Convenience Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-liner to create fitter from config file\n",
    "config_path = Path(\"../config/example.conf\")\n",
    "\n",
    "if config_path.exists():\n",
    "    # Load fitter with all configs in one line\n",
    "    fitter_from_config = DistributionFitter.from_config(str(config_path))\n",
    "    \n",
    "    print(\"Fitter created from config file:\")\n",
    "    print(f\"  fit.bins: {fitter_from_config.config.bins}\")\n",
    "    print(f\"  plot_config available: {fitter_from_config.plot_config is not None}\")\n",
    "    \n",
    "    # The plot_config is automatically loaded\n",
    "    if fitter_from_config.plot_config:\n",
    "        print(f\"  plot.dpi: {fitter_from_config.plot_config.dpi}\")\n",
    "else:\n",
    "    print(\"Config file not found - run from examples/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Working with Results\n",
    "\n",
    "The `fit()` method returns a `FitResults` object for easy result manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Getting Best Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best distribution by SSE (default)\n",
    "best_sse = results_normal.best(n=1)[0]\n",
    "print(f\"Best by SSE: {best_sse.distribution}\")\n",
    "print(f\"  SSE: {best_sse.sse:.6f}\")\n",
    "print(f\"  AIC: {best_sse.aic:.2f}\")\n",
    "print(f\"  BIC: {best_sse.bic:.2f}\")\n",
    "print(f\"  Parameters: {[f'{p:.4f}' for p in best_sse.parameters]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 by different metrics\n",
    "print(\"\\nTop 5 by SSE:\")\n",
    "for i, r in enumerate(results_normal.best(n=5, metric=\"sse\"), 1):\n",
    "    print(f\"  {i}. {r.distribution:20s} SSE={r.sse:.6f}\")\n",
    "\n",
    "print(\"\\nTop 5 by AIC:\")\n",
    "for i, r in enumerate(results_normal.best(n=5, metric=\"aic\"), 1):\n",
    "    print(f\"  {i}. {r.distribution:20s} AIC={r.aic:.2f}\")\n",
    "\n",
    "print(\"\\nTop 5 by BIC:\")\n",
    "for i, r in enumerate(results_normal.best(n=5, metric=\"bic\"), 1):\n",
    "    print(f\"  {i}. {r.distribution:20s} BIC={r.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Filtering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by SSE threshold\n",
    "good_fits = results_normal.filter(sse_threshold=0.01)\n",
    "print(f\"Distributions with SSE < 0.01: {good_fits.count()}\")\n",
    "\n",
    "for r in good_fits.best(n=10):\n",
    "    print(f\"  {r.distribution:20s} SSE={r.sse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Converting to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame for further analysis\n",
    "df_results = results_normal.to_pandas()\n",
    "print(\"Results as pandas DataFrame:\")\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Using Fitted Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FitResult object wraps the scipy.stats distribution\n",
    "best = results_normal.best(n=1)[0]\n",
    "\n",
    "# Generate samples from the fitted distribution\n",
    "samples = best.sample(size=10000, random_state=42)\n",
    "print(f\"Generated {len(samples)} samples from fitted {best.distribution}\")\n",
    "print(f\"  Sample mean: {samples.mean():.2f} (original: {normal_data.mean():.2f})\")\n",
    "print(f\"  Sample std: {samples.std():.2f} (original: {normal_data.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PDF at specific points\n",
    "x = np.array([30, 40, 50, 60, 70])\n",
    "pdf_values = best.pdf(x)\n",
    "cdf_values = best.cdf(x)\n",
    "\n",
    "print(\"\\nPDF and CDF values:\")\n",
    "for xi, pdf, cdf in zip(x, pdf_values, cdf_values):\n",
    "    print(f\"  x={xi}: PDF={pdf:.6f}, CDF={cdf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Plotting\n",
    "\n",
    "Visualize the fitted distribution with the data histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Basic Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plot with default config\n",
    "fig, ax = fitter.plot(\n",
    "    best,\n",
    "    df_normal,\n",
    "    \"value\",\n",
    "    title=\"Best Fit Distribution (Normal Data)\",\n",
    "    xlabel=\"Value\",\n",
    "    ylabel=\"Density\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Plot with Custom PlotConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom plot configuration\n",
    "custom_plot_config = PlotConfig(\n",
    "    figsize=(14, 8),\n",
    "    dpi=100,\n",
    "    histogram_alpha=0.7,\n",
    "    pdf_linewidth=3,\n",
    "    title_fontsize=18,\n",
    "    label_fontsize=14,\n",
    "    legend_fontsize=12,\n",
    "    grid_alpha=0.4,\n",
    ")\n",
    "\n",
    "fig, ax = fitter.plot(\n",
    "    best,\n",
    "    df_normal,\n",
    "    \"value\",\n",
    "    config=custom_plot_config,\n",
    "    title=\"Distribution Fit with Custom Styling\",\n",
    "    xlabel=\"Value\",\n",
    "    ylabel=\"Density\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Plot Non-Negative Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fit for exponential data\n",
    "best_exp = results_exp.best(n=1)[0]\n",
    "print(f\"Best fit for exponential data: {best_exp.distribution}\")\n",
    "\n",
    "fig, ax = fitter_nonneg.plot(\n",
    "    best_exp,\n",
    "    df_exp,\n",
    "    \"value\",\n",
    "    config=custom_plot_config,\n",
    "    title=f\"Best Fit: {best_exp.distribution.capitalize()}\",\n",
    "    xlabel=\"Value\",\n",
    "    ylabel=\"Density\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Complete Workflow Example\n",
    "\n",
    "Putting it all together - a complete production-style workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config as HOCON string (could also be loaded from file)\n",
    "production_config = \"\"\"\n",
    "spark {\n",
    "    app_name = \"production-fitting\"\n",
    "    arrow_enabled = true\n",
    "    adaptive_enabled = true\n",
    "}\n",
    "\n",
    "fit {\n",
    "    bins = 100\n",
    "    use_rice_rule = false\n",
    "    support_at_zero = false\n",
    "    enable_sampling = true\n",
    "    max_sample_size = 1000000\n",
    "    random_seed = 42\n",
    "}\n",
    "\n",
    "plot {\n",
    "    figsize = [14, 9]\n",
    "    dpi = 150\n",
    "    histogram_alpha = 0.6\n",
    "    pdf_linewidth = 3\n",
    "    title_fontsize = 16\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Load config\n",
    "config = AppConfig.from_string(production_config)\n",
    "\n",
    "# Create fitter with config\n",
    "fitter = DistributionFitter(config=config.fit, spark_config=config.spark)\n",
    "\n",
    "# Fit distributions\n",
    "print(\"Fitting gamma distribution data...\")\n",
    "results = fitter.fit(df_gamma, column=\"value\", max_distributions=25)\n",
    "\n",
    "# Get best result\n",
    "best = results.best(n=1)[0]\n",
    "print(f\"\\nBest distribution: {best.distribution}\")\n",
    "print(f\"SSE: {best.sse:.6f}\")\n",
    "print(f\"Parameters: {[f'{p:.4f}' for p in best.parameters]}\")\n",
    "\n",
    "# Plot with config\n",
    "fig, ax = fitter.plot(\n",
    "    best,\n",
    "    df_gamma,\n",
    "    \"value\",\n",
    "    config=config.plot,\n",
    "    title=f\"Gamma Data - Best Fit: {best.distribution.capitalize()}\",\n",
    "    xlabel=\"Value\",\n",
    "    ylabel=\"Density\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Show top 5 results\n",
    "print(\"\\nTop 5 distributions:\")\n",
    "df_top5 = results.to_pandas().head(5)\n",
    "df_top5[[\"distribution\", \"sse\", \"aic\", \"bic\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"Spark session stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Configuration Classes**:\n",
    "   - `FitConfig` - Distribution fitting parameters\n",
    "   - `PlotConfig` - Visualization settings\n",
    "   - `SparkConfig` - Spark session configuration\n",
    "   - `AppConfig` - Container for nested configs\n",
    "\n",
    "2. **Config Loading**:\n",
    "   - `FitConfig()` - Direct instantiation\n",
    "   - `FitConfig.from_string()` - From HOCON/YAML/JSON string\n",
    "   - `AppConfig.from_file()` - From nested config file\n",
    "   - `DistributionFitter.from_config()` - One-liner convenience method\n",
    "\n",
    "3. **Fitting**:\n",
    "   - `DistributionFitter.fit()` - Fit distributions to data\n",
    "   - `max_distributions` parameter to limit fitting scope\n",
    "   - `support_at_zero` for non-negative data\n",
    "\n",
    "4. **Results**:\n",
    "   - `results.best(n, metric)` - Get top N by SSE/AIC/BIC\n",
    "   - `results.filter()` - Filter by threshold\n",
    "   - `results.to_pandas()` - Convert to pandas DataFrame\n",
    "   - `FitResult.sample()`, `.pdf()`, `.cdf()` - Use fitted distribution\n",
    "\n",
    "5. **Plotting**:\n",
    "   - `fitter.plot()` - Visualize fitted distribution with data histogram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
